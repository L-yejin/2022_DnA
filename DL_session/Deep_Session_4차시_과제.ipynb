{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67275c",
   "metadata": {},
   "source": [
    "# Deep Session 4차시 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e8d5a",
   "metadata": {},
   "source": [
    "# LeNet 구현해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07562d02",
   "metadata": {},
   "source": [
    "<img src='http://drive.google.com/uc?export=view&id=1MevERvWOuYttJyTaFbGDJggB3luPD0TP' /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b077d",
   "metadata": {},
   "source": [
    "LeNet-5는 32x32 크기의 흑백 이미지에서 학습된 7 layer Convolutional Neural Network  \n",
    "\n",
    "[Conv(C1) - Subsampling(S2) - Conv(C3) - Subsampling(S4) - Conv(C5) - FC - FC]  \n",
    "\n",
    "**Input**  \n",
    "입력 이미지는 32x32  \n",
    "**Layer C1**  \n",
    "5x5 크기의 kernel 6개와 stride=1, convolutional layer  \n",
    "입력 크기는 32x32x1 이고, 출력 크기는 28x28x6  \n",
    "**Layer S2**\n",
    "2x2 크기의 kernel 6개와 stride=2, subsampling layer  \n",
    "입력 크기는 28x28x6 이고, 출력 크기는 14x14x6  \n",
    "**Layer C3**  \n",
    "5x5 크기의 kernel 16개와 stride=1, convolution layer  \n",
    "입력 크기는 14x14x6 이고, 출력 크기는 10x10x16  \n",
    "**Layer S4**  \n",
    "2x2 크기의 kernel 16개와 stride=2, subsampling layer  \n",
    "입력 크기는 10x10x16 이고, 출력 크기는 5x5x16  \n",
    "**Layer C5**  \n",
    "5x5 크기의 kernel 120개와 stride=1, convolutional layer  \n",
    "입력 크기는 5x5x16 이고, 출력 크기는 1x1x120  \n",
    "**Layer F6**  \n",
    "tanh 함수를 활성화 함수로 이용하는 fully-connected layer  \n",
    "입력 유닛은 120개 이고, 출력 유닛은 84개  \n",
    "**Layer F7**  \n",
    "RBF(Euclidean Radia Basis Function unit)를 활성화 함수로 이용하는 output layer  \n",
    "입력 크기는 84 이고, 출력 크기는 10  \n",
    "**Loss function**  \n",
    "Loss function은 MSE(평균 제곱 오차)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182459db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters 설정\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.1\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e728c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  정확도를 구하는 function과 손실을 시각화 하는 function 정의\n",
    "\n",
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    전체 data_loader에 대한 예측의 정확도를 계산하는 함수\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            _, y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    training과 validation loss를 시각화하는 함수\n",
    "    '''\n",
    "    \n",
    "    # plot style을 seaborn으로 설정\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # plot style을 기본값으로 설정\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data에 사용되는 helper 함수 정의하기\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    training loop의 training 단계에 대한 함수\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # 순전파\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccbece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data에 사용되는 함수 정의\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    training loop의 validation 단계에 대한 함수\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # 순전파와 손실 기록하기\n",
    "        y_hat, _ = model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416aa0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop 정의\n",
    "\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    전체 training loop를 정의하는 함수\n",
    "    '''\n",
    "    \n",
    "    # metrics를 저장하기 위한 객체 설정\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    " \n",
    "    # model 학습하기\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 준비하기\n",
    "\n",
    "# transforms 정의하기\n",
    "transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# data set 다운받고 생성하기\n",
    "train_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=True, \n",
    "                               transform=transforms,\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=False, \n",
    "                               transform=transforms)\n",
    "\n",
    "# data loader 정의하기\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인 1\n",
    "\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7840f47",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple\">이부분 채우기</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 구조 정의 \n",
    "# nn.Conv2d, nn.AvgPool2d, nn.Linear를 이용해서 입력 이미지가 각 층을 통과하는 모양으로 만들기\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # 이 부분 채우기\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이 부분 채우기\n",
    "        x = \n",
    "        \n",
    "        probs = F.softmax(x, dim=1)\n",
    "        return x, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12919e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 구조 정의 \n",
    "# nn.Sequential을 이용해서 ()괄호 안에 층들을 쌓아서 만들기\n",
    "\n",
    "class LeNet5_Sequential(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5_Sequential, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential( \n",
    "            \n",
    "            # 이 부분 채우기\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            \n",
    "            # 이 부분 채우기\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이 부분 채우기\n",
    "        x = \n",
    "        \n",
    "        probs = F.softmax(x, dim=1)\n",
    "        return x, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517edbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer, loss function 설정하기\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "#model = LeNet5().to(DEVICE)\n",
    "model = LeNet5_Sequential().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc67654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 학습\n",
    "\n",
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, \n",
    "                                    valid_loader, N_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7237f",
   "metadata": {},
   "source": [
    "### 추가적으로 seed, learning_rate, batch_size, epoch 값 등 변경해보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
